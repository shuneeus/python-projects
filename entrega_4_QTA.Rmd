---
title: "4ta entrega dom√©stica QTA"
author: "Luis Sebastian Huneeus"
date: "31 de mayo de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
pacman::p_load("haven", "tidyverse", "textclean", "stringr", "tm", "quanteda", "NLP", "austin", "tidytext")

```

# llamamos a la base de datos con los tweets 
```{r}
tweets<-readRDS("03_o_tweets_01_extr_2018-04-12.rds")

tweets2<-tweets %>%  select( user_id, screen_name, text, 
                           is_retweet) %>%
                           filter(user_id > 600000000) %>% 
                           group_by(user_id)



tweets3<- tweets2 %>%  group_by(screen_name) %>%  summarize(bag_of_words = paste(text, collapse = ",")) 


```



```{r}
#antes de eliminar putuaciones, debo eliminar todos los usuarios (palabras que empiezan con @)


#ahora eliminamos puntuaciones
tweets4<-gsub('[[:punct:]]',' ', tweets$text)

tweets4df<-as.data.frame(tweets4)

```



```{r}
# remuevo stopwords

```


```{r}
# PARA AUSTIN
# genero un corpus para limpiar texto con paquete TM y NLP 

tweets_corpus<-Corpus(VectorSource(tweets3))
tweets_corpus<- tm_map(tweets_corpus, content_transformer(tolower)) # a minuscula
tweets_corpus <- tm_map(tweets_corpus, removeWords, stopwords("spanish")) # remueve stopwords
tweets_corpus <- tm_map(tweets_corpus, stemDocument) # stems
tweets_corpus<- tm_map(tweets_corpus, removePunctuation) # saca puntuaciones
tweets_corpus <- tm_map(tweets_corpus, removeNumbers) # saca los numeros 

tweets_dtm<-DocumentTermMatrix(tweets_corpus)

#no converge algoritmo
wordfish <- wordfish(as.wfm(tweets_dtm), dir=c(33, 4), control = list(tol = .03))



ggplot(mapping = aes(y = wordfish$theta, x = tweets2$screen_name, color=tweets2$screen_name)) + geom_point() + labs(x = "Claimed Ideology", y = "Wordfish theta") + guides(col = guide_legend(title = "Claimed Ideology"))


# dado que no converge, estimadores no dan positivos. Pesos (betas) y frecuencias (psi)
# problema es que genera un documento distinto para cada tuit: hay que combinar los twuits de cada usuario. 
# o de cada partido. 

imptntwords.wf <- which(wordfish$beta > 0 & wordfish$psi > 0)

ggplot(mapping = aes(x = wordfish$beta[imptntwords.wf], y = wordfish$psi[imptntwords.wf], label = 
wordfish$words[imptntwords.wf])) + geom_text(size = 1) + labs(x = "Beta", y = "Psi")

```


```{r}
# PARA QUANTEDA
# genero un DFM  (document feature matrix) a partir de un objeto CORPUS de QUANTEDA. 


corpus_q<-corpus(tweets_corpus, metacorpus = NULL, compress = FALSE)

corpus_q1<-corpus(tweets_corpus, text_field = "bag_of_words")

corpus_q2<-corpus(tweets3, text_field = "bag_of_words", metacorpus =  tweets3)

dfm<-dfm(corpus_q2)

wf <- textmodel_wordfish(dfm)

summary(wf)

ggplot(mapping = aes(y = wf$theta, x = tweets3$screen_name, color=tweets3$screen_name)) + geom_point() + labs(x = "Claimed Ideology", y = "Wordfish theta") + guides(col = guide_legend(title = "Claimed Ideology"))


imptntwords.wf.q <- which(wf$beta > 0 & wf$psi > 0)

ggplot(mapping = aes(x = wf$beta[imptntwords.wf.q], y = wf$psi[imptntwords.wf.q], label = 
wf$words[imptntwords.wf.q])) + geom_text(size = 1) + labs(x = "Beta", y = "Psi")



```
